# -*- coding: utf-8 -*-
"""streamlit run data_analysis_app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17ZQaIyFf63gZ7f3vfARDuMZ5JmcPm3-r
"""

pip install streamlit pandas numpy plotly seaborn scikit-learn openpyxl

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# Set page config
st.set_page_config(
    page_title="Universal Data Analysis App",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .metric-container {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
    }
    .section-header {
        color: #1f77b4;
        font-size: 1.5rem;
        font-weight: bold;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .insight-box {
        background-color: #e8f4f8;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Main title
st.markdown('<h1 class="main-header">üìä Universal Data Analysis App</h1>', unsafe_allow_html=True)
st.markdown('<p style="text-align: center; color: #666; font-size: 1.2rem;">Upload any dataset and get instant visual insights with AI-powered analysis</p>', unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.header("üîß Settings")
    uploaded_file = st.file_uploader("Upload your dataset", type=["csv", "xlsx", "xls"])
    st.subheader("Analysis Options")
    show_basic_stats = st.checkbox("Basic Statistics", True)
    show_correlations = st.checkbox("Correlation Analysis", True)
    show_distributions = st.checkbox("Distribution Analysis", True)
    show_clustering = st.checkbox("Clustering Analysis", False)
    show_time_series = st.checkbox("Time Series Analysis", False)
    st.subheader("Chart Customization")
    color_palette = st.selectbox("Color Palette", ["plotly", "viridis", "plasma", "cividis", "turbo", "rainbow"])
    chart_height = st.slider("Chart Height", 300, 800, 500)

# Functions
def load_data(file):
    try:
        if file.name.endswith('.csv'):
            return pd.read_csv(file)
        else:
            return pd.read_excel(file)
    except Exception as e:
        st.error(f"Error loading file: {e}")
        return None

def detect_column_types(df):
    numeric = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical = df.select_dtypes(include=['object']).columns.tolist()
    datetime_cols = []
    for col in categorical:
        try:
            pd.to_datetime(df[col].dropna().iloc[:100])
            datetime_cols.append(col)
        except:
            pass
    categorical = [col for col in categorical if col not in datetime_cols]
    return numeric, categorical, datetime_cols

def create_overview_metrics(df):
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.markdown(f"""<div class="metric-container"><h3>üìè Rows</h3><h2>{df.shape[0]:,}</h2></div>""", unsafe_allow_html=True)
    with col2:
        st.markdown(f"""<div class="metric-container"><h3>üìä Columns</h3><h2>{df.shape[1]:,}</h2></div>""", unsafe_allow_html=True)
    with col3:
        st.markdown(f"""<div class="metric-container"><h3>üî¢ Numeric</h3><h2>{len(df.select_dtypes(include=[np.number]).columns)}</h2></div>""", unsafe_allow_html=True)
    with col4:
        missing_pct = df.isnull().sum().sum() / (df.shape[0]*df.shape[1]) * 100
        st.markdown(f"""<div class="metric-container"><h3>‚ùå Missing</h3><h2>{missing_pct:.1f}%</h2></div>""", unsafe_allow_html=True)

def generate_insights(df, numeric_cols, categorical_cols):
    st.markdown('<div class="section-header">üß† Automated Insights</div>', unsafe_allow_html=True)
    insights = []
    missing = df.isnull().sum()
    if missing.sum() > 0:
        col = missing.idxmax()
        insights.append(f"‚ö†Ô∏è '{col}' has most missing values ({missing[col]} rows, {missing[col]/len(df)*100:.1f}%)")
    for col in numeric_cols[:3]:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        outliers = df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)]
        if not outliers.empty:
            insights.append(f"üìä '{col}' has {len(outliers)} potential outliers ({len(outliers)/len(df)*100:.1f}%)")
    if len(numeric_cols) > 1:
        corr = df[numeric_cols].corr().abs().unstack().sort_values(ascending=False)
        corr = corr[corr < 1.0]
        if len(corr) > 0 and corr.iloc[0] > 0.8:
            pair = corr.index[0]
            insights.append(f"üîó Strong correlation ({corr.iloc[0]:.2f}) between '{pair[0]}' and '{pair[1]}'")
    for col in categorical_cols[:2]:
        count = df[col].nunique()
        common = df[col].mode()[0] if len(df[col].mode()) > 0 else "N/A"
        freq = (df[col] == common).sum() / len(df) * 100
        insights.append(f"üìã '{col}' has {count} unique values. Most common: '{common}' ({freq:.1f}%)")
    for i in insights:
        st.markdown(f'<div class="insight-box">{i}</div>', unsafe_allow_html=True)

def create_distribution_plots(df, numeric_cols, categorical_cols):
    st.markdown('<div class="section-header">üìà Distribution Analysis</div>', unsafe_allow_html=True)
    if numeric_cols:
        fig = make_subplots(rows=(len(numeric_cols)+2)//3, cols=3, subplot_titles=numeric_cols)
        for i, col in enumerate(numeric_cols):
            fig.add_trace(go.Histogram(x=df[col], name=col), row=i//3+1, col=i%3+1)
        fig.update_layout(height=chart_height*len(numeric_cols)//3, title="Distributions")
        st.plotly_chart(fig, use_container_width=True)
    if categorical_cols:
        for col in categorical_cols[:2]:
            counts = df[col].value_counts().head(10)
            col1, col2 = st.columns(2)
            with col1:
                st.plotly_chart(px.bar(x=counts.values, y=counts.index, orientation='h', title=f"Top in {col}"), use_container_width=True)
            with col2:
                st.plotly_chart(px.pie(values=counts.values, names=counts.index, title=f"{col} Distribution"), use_container_width=True)

def create_correlation_analysis(df, numeric_cols):
    st.markdown('<div class="section-header">üîó Correlation Analysis</div>', unsafe_allow_html=True)
    if len(numeric_cols) > 1:
        corr = df[numeric_cols].corr()
        fig = px.imshow(corr, text_auto=True, color_continuous_scale=color_palette)
        fig.update_layout(height=chart_height)
        st.plotly_chart(fig, use_container_width=True)

def create_time_series_analysis(df, datetime_cols, numeric_cols):
    if not datetime_cols or not numeric_cols:
        return
    st.markdown('<div class="section-header">‚è±Ô∏è Time Series Analysis</div>', unsafe_allow_html=True)
    date_col = datetime_cols[0]
    df[date_col] = pd.to_datetime(df[date_col])
    for col in numeric_cols[:3]:
        fig = px.line(df.sort_values(date_col), x=date_col, y=col, title=f"{col} over time")
        fig.update_layout(height=chart_height//2)
        st.plotly_chart(fig, use_container_width=True)

def create_clustering_analysis(df, numeric_cols):
    if len(numeric_cols) < 2:
        return
    st.markdown('<div class="section-header">üéØ Clustering Analysis</div>', unsafe_allow_html=True)
    X = df[numeric_cols].fillna(df[numeric_cols].mean())
    X_scaled = StandardScaler().fit_transform(X)
    inertias = []
    for k in range(1, 6):
        inertias.append(KMeans(n_clusters=k).fit(X_scaled).inertia_)
    fig = go.Figure(data=go.Scatter(x=list(range(1, 6)), y=inertias, mode='lines+markers'))
    fig.update_layout(title="Elbow Curve", height=chart_height//2)
    st.plotly_chart(fig, use_container_width=True)
    kmeans = KMeans(n_clusters=3)
    df["Cluster"] = kmeans.fit_predict(X_scaled)
    pca = PCA(n_components=2).fit_transform(X_scaled)
    fig = px.scatter(x=pca[:, 0], y=pca[:, 1], color=df["Cluster"].astype(str), title="KMeans PCA View")
    st.plotly_chart(fig, use_container_width=True)

# MAIN LOGIC
if uploaded_file:
    df = load_data(uploaded_file)
    if df is not None:
        st.success(f"‚úÖ Data loaded. Shape: {df.shape}")
        create_overview_metrics(df)
        numeric_cols, categorical_cols, datetime_cols = detect_column_types(df)
        col1, col2, col3 = st.columns(3)
        with col1: st.info(f"**Numeric ({len(numeric_cols)}):** {', '.join(numeric_cols[:5])}")
        with col2: st.info(f"**Categorical ({len(categorical_cols)}):** {', '.join(categorical_cols[:5])}")
        with col3: st.info(f"**Datetime ({len(datetime_cols)}):** {', '.join(datetime_cols[:5])}")
        st.markdown('<div class="section-header">üëÄ Data Preview</div>', unsafe_allow_html=True)
        st.dataframe(df.head(), use_container_width=True)
        generate_insights(df, numeric_cols, categorical_cols)
        if show_basic_stats: st.dataframe(df[numeric_cols].describe(), use_container_width=True)
        if show_distributions: create_distribution_plots(df, numeric_cols, categorical_cols)
        if show_correlations: create_correlation_analysis(df, numeric_cols)
        if show_time_series: create_time_series_analysis(df, datetime_cols, numeric_cols)
        if show_clustering: create_clustering_analysis(df, numeric_cols)